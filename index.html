<!doctype html>
<html>

<head>
	
	<!-- Mapbox reference -->
	<link href="https://api.mapbox.com/mapbox-gl-js/v2.1.1/mapbox-gl.css" rel="stylesheet">
	<script src="https://api.mapbox.com/mapbox-gl-js/v2.1.1/mapbox-gl.js"></script>
	
	<!-- Our stylesheet  -->
	<link href='./style.css' rel='stylesheet'>

	<!-- Our metadata -->
	<meta charset="utf-8">
	<title> IDV Project II: Mapping the Twitterverse </title>
	<meta name="viewport" content="initial-scale=1,maximum-scale=1,user-scalable=no">
</head>


<body>
	<h1> Mapping the Twitterverse: Wildlife Safari Edition </h1>
	<h2> Where's the wildlife? </h2>
	<div id="intro" class="text">
		<p> 
			Wildlife is all around us. Sometimes we take notice and note them on <a href='https://www.twitter.com/'>Twitter</a>. This project showcases the tweets that included "wildlife" in various languages listed below between March 13, 2021 and March 19, 2021.
			<ul>
				<li>Arabic</li>
				<li>English</li>
				<li>French</li>
				<li>Indonesian</li>
				<li>Portuguese</li>
				<li>Spanish</li>
				<li>Thai</li>
			</ul>
		</p>
	</div>
	
	<!-- display map -->
	<div id="map" class="viz"> </div>

	<!-- display tweet deets -->
	<div class='tweetBox'>
	    <div><strong>Tweet:</strong> <span id='tweet'></span></div>
	    <div><strong>User:</strong> <span id='user'></span></div>
	    <div><strong>Date:</strong> <span id='date'></span></div>
	</div>
	
	<!-- display filter menu -->
	<div id='menu' -->
	
	<!--build map with Mapbox GL JS script -->
	<script>
         
	    mapboxgl.accessToken = 'pk.eyJ1IjoiYW5uYS1uaXJ2YW5hIiwiYSI6ImNraWNkdTNnbDBxN2wyeGw2NWNwd3k0d2EifQ.fkhFRK0trir8P5JOg82OXA';
	    var map = new mapboxgl.Map({
	    container: 'map', // container id
	    style: 'mapbox://styles/anna-nirvana/ckmnzli9f7g1517qlg3wunr12', // custom style url from https://studio.mapbox.com/
	    center: [5, 15], // starting position
	    zoom: 2, // starting zoom
	    layout: {
	    // make layer visible by default
	    'visibility': 'visible',
	    }
	    });

	    // EXPERIMENTAL FILTER CODE
	    //enumerate ids of the layers
	    var toggleableLayerIds = ['Arabic','English','French','Indonesian','Portuguese','Spanish','Thai'];

	    // set up the corresponding toggle button for each layer
	    for (var i = 0; i < toggleableLayerIds.length; i++) {
	    var id = toggleableLayerIds[i];

	    var link = document.createElement('a');
	    link.href = '#';
	    link.className = 'active';
	    link.textContent = id;

	    link.onclick = function (e) {
	    var clickedLayer = this.textContent;
	    e.preventDefault();
	    e.stopPropagation();

	    var visibility = map.getLayoutProperty(clickedLayer, 'visibility');

	    //toggle layer visibility by changing the layout object's visibility property
	    if (visibility === 'visible') {
		map.setLayoutProperty(clickedLayer, 'visibility', 'none');
	    this.className = '';
	    } else {
	    this.className = 'active';
	    map.setLayoutProperty(clickedLayer, 'visibility', 'visible');
	    }
	    };

	    var layers = document.getElementById('menu');
	    layers.appendChild(link);
	    }

	</script>
	</div>

	<div id="process" class="text"></div>
	<h3> Here's a list of the steps we took to complete this project. </h3>
	<ol>
		<li> <b> Step 1: </b> Collected data using Twitter's API using the below code</li>
		<li> <b> Step 2: </b> Converted the data from a JSON file to an EXCEL file for clean-up</li>
		<li> <b> Step 3: </b> Converted the cleaned-up EXCEL file into a CSV file</li>
		<li> <b> Step 4: </b> Uploaded the CSV file into <a href='https://www.mapbox.com/mapbox-studio'>Mapbox</a> and created a map</li>
		<li> <b> Step 5: </b> Created a GitHub repository and page</li>
		<li> <b> Step 6: </b> Embedded the map into HTML file within GitHub repository</li>
		<li> <b> Step 7: </b> Cleaned-up GitHub page</li>
	</ol>

	<h3> Here's our code: </h3>
	<p> Here's a sample of the code we used to scrape Twitter. </p>
	
	<pre>
		const needle = require('needle'); // requires library to make HTTP requests \n
		const fs = require('fs'); // requires library to save files \n
		const token = "YOUR_BEARER_TOKEN"; // this is your bearer token \n

		const endpointUrl = "https://api.twitter.com/2/tweets/search/recent"; // End-point for recent search \n
		//const endpointUrl = "https://api.twitter.com/2/tweets/search/all"; // This would be the end-point for the full historical search, only available for academic licenses \n


		/** This function simply puts a request given a certain 'query' \n
		 *  and a batch of paginated results indicated in 'nextToken' */ \n

		async function getRequest(query, nextToken) { \n

		    // builds a query object to send \n
		    function buildQuery() { \n
			let q = { \n
			    "query": query,     // the query \n
			    "max_results": 100, // max results per request, 100 is the maximum for standard licenses in sandboxed environments \n
			    "expansions": "geo.place_id",   // whenever a tweet has geographical information in the form a of place_id, get more info on that place_id \n
			    "tweet.fields": "author_id,created_at,geo",     // by default the Tweet id and and the text are returned, but here we're also including the author_id, the time of publishing, and its geographical features \n
			    "place.fields": "geo,name,full_name,place_type" // the additional information associated with a place_id, namely its name and a geo object with geographical coordinates, either in the form of a point or a bounding box \n
			}; \n
			// the nextToken paramenter is optional (as there is none in the first request \n
			// but if a nextToken was passed, then it inserts it into the query object \n
			if(nextToken !== undefined) q["next_token"] = nextToken; \n
			return q; \n
		    }

		    const response = await needle('get', endpointUrl, buildQuery(), {
			headers: {
			    "User-Agent": "v2RecentSearchJS",   // Can be whatver you want
			    "authorization": "Bearer "+token    // Attaches your Bearer token to the header of the request
			}
		    })
		    return response.body;   // Returns the contents of the response
		}


		/** async funtions enable us to stop the program to wait on requests
		 *  this function is the core of the program and where execution starts */

		(async function(){

		    /** an anonymous function that gets a whole batch of tweet reponses
		     *  and only adds the ones with geo information to 'array' */
		    function filterTweets(array, batch){
			batch.data.forEach(tweet => {
			    if(tweet["geo"] !== undefined){
				/* expands place_id */
				if(tweet.geo["place_id"] !== undefined){
				    /* associates the place_id with the expanded information on place_ids in the response */
				    let expanded_geo = batch.includes.places.find( place => {
					return place.id == tweet.geo.place_id;
				    });
				    // adds new variable to tweet object called 'place_info'
				    tweet.place_info = expanded_geo;
				}
				if(tweet['place_info']['geo']['bbox'] ==! undefined){
				    //average of the bbox
				    /*
					bbox[0] -> x of bottom left corner
					bbox[1] -> y of bottom left corner
					bbox[2] -> x of top right corner
					bbox[3] -> y of top right corner

				    */

				    let xa = (tweet.place_info.geo.bbox[0] + tweet.place_info.geo.bbox[2])/2
				    let ya = (tweet.place_info.geo.bbox[1] + tweet.place_info.geo.bbox[3])/2

				    tweet.place_info.geo.center = [xa, ya];

				}
				array.push(tweet);
			    }
			});

		    }

		    let filteredTweets = []; //array to keep all collected tweets

		    const query = "wildlife -is:retweet";       // we are searching for the word 'wildlife' but only in tweets that are *not* retweets since retweets never have geo information
		    let response = await getRequest(query); // finally, put the request and wait for the response
		    //console.log(response); // DEBUG
		    const nGeoTweets = 200;     // after how many collected tweets with geo info are stopping execution>
		    while(response.meta["next_token"] !== undefined){
			response = await getRequest(query, response.meta.next_token);
			filterTweets(filteredTweets, response);
			console.log(filteredTweets.length); // DEBUG
			await sleep(2100);  /*  sleeps the program for 2.1seconds : 
						the standard rate limit is 450 requests per 15 min time period.
						If you make more than 450 requests in less than 15 mins, the API
						will block further requests until the 15 mins period is over;
						Since the percentage of tweets with geo information is low you will 
						need to place more than 450 requets (remember that each requests returns 100 tweets)
						In order to stay under the rate limit and leave the program executing in the
						background collecting tweets, only one request every 2 seconds should be placed */

			//  if we have enough tweets, stops collecting                        
			if(filteredTweets.length >= nGeoTweets) break;

		    }

		    console.log("TWEETS WITH GEO: " +filteredTweets.length); // DEBUG
		    console.log(filteredTweets); // DEBUG
		    fs.writeFileSync("wildlife.json", JSON.stringify(filteredTweets)); // Save the results to a file in the disk
		    process.exit(); // terminates the program
		})();

		/** Utility function that sleeps the program for 'ms' milliseconds */
		function sleep(ms) {
		    return new Promise(resolve => setTimeout(resolve, ms));
		}
	</pre>
	</div>

	<h3> Chart </h3>
	<div id="chart" class="viz">

		<h3></h3>
		<h3>a placeholder for the chart</h3>
		<h3></h3>
	</div>

</body>
</html>
